# -*- coding: utf-8 -*-
"""
tensorflow.kerasで分類モデル作成
ディレクトリやパラメータはget_class_fine_tuning_parameter_base()で変更する
Usage:
    # 指定ディレクトリについてgenerator作ってモデル学習
    $ python tf_base_class_all_data.py -m train

    # 指定ディレクトリについてモデル予測
    $ python tf_base_class_all_data.py -m predict

    # optunaでパラメータチューニング
    # 変更するパラメータは Objective.get_class_fine_tuning_parameter_suggestions() で変更する
    $ python tf_base_class_all_data.py -m tuning -n_t 100 -t_out_dir D:\work\signal_model\output\model\tf_base_class_all_py_time_series\optuna
"""
import os
import sys
import time
import shutil
import argparse
import traceback
import pathlib

import optuna
import numpy as np
import pandas as pd
from tqdm import tqdm

# tensorflowのINFOレベルのログを出さないようにする
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator

keras_py_path = r'C:\Users\81908\jupyter_notebook\tfgpu_py36_work\02_keras_py'
sys.path.append(keras_py_path)
from dataset import plot_log, util
from model import tf_define_model as define_model
from model import tf_my_callback as my_callback
from model import tf_lr_finder as lr_finder
from model import tf_pooling as pooling
from transformer import tf_my_generator as my_generator
from transformer import tf_get_train_valid_test as get_train_valid_test
from predicter import tf_grad_cam as grad_cam
from predicter import tf_base_predict as base_predict
from predicter import roc_curve, conf_matrix, ensemble_predict

sys.path.append(r'C:\Users\81908\jupyter_notebook\tf_2_work\stock_work\signal_model\code')
import model_2d


def label2onehot(labels: np.ndarray):
    """
    sklearnでnp.ndarrayのラベルをonehot化
    Args:
        labels:onehot化するラベル名の配列.np.array(['high' 'high' 'low' 'low'])のようなの
    Returns:
        enc:ラベル名を0-nの連番にした配列。np.array([[0] [0] [1] [1]])のようなの
        onehot:ラベル名をonehotにした配列。np.array([[1. 0.] [1. 0.] [0. 1.] [0. 1.]])のようなの
    Usage:
        labels = df['aaa'].values
        enc, onehot = label2onehot(labels)
    """
    from sklearn import preprocessing
    from sklearn.preprocessing import OneHotEncoder

    enc = preprocessing.LabelEncoder().fit_transform(labels).reshape(-1,1)
    onehot = OneHotEncoder().fit_transform(enc).toarray()
    return enc, onehot


def get_dataset(classes=['0', '1', '2'],
                dataset_dir=r'D:\work\signal_model\output\dataset\all'):
    """データセット取得"""
    def _set(set_name: str):
        X_set, y_set = None, None
        for cla in classes:
            X = np.load(os.path.join(dataset_dir, f'class_{cla}_{set_name}.npy'))
            y = np.array([cla] * X.shape[0])
            if X_set is None and y_set is None:
                X_set = X
                y_set = y
            else:
                X_set = np.append(X_set, X, axis=0)
                y_set = np.append(y_set, y, axis=0)

        _, y_set = label2onehot(y_set)
        return X_set, y_set

    X_train, y_train = _set('train')
    X_valid, y_valid = _set('val')
    X_test, y_test = _set('test')
    return X_train, y_train, X_valid, y_valid, X_test, y_test


def get_class_fine_tuning_parameter_base() -> dict:
    """
    Get parameter sample for class fine_tuning (like Keras)
    Returns:
        dict: parameter sample generated by trial object
    """
    my_IDG_options = {
        #'rescale': 1.0 / 255.0,
        #'width_shift_range': 0.2,
        #'height_shift_range': 0.2,
        #'horizontal_flip': True,
        #'vertical_flip': True,
        #'shear_range': 20,
        #'zoom_range': 0.2,
        #'rotation_range': 20,
        #'channel_shift_range': 50,
        #'brightness_range': [0.3, 1.0],
        #'random_erasing_prob': 0.5,
        #'random_erasing_maxpixel': 255,
        #'mix_up_alpha': 0.2,
        #'random_crop': [224,224],
        #'ricap_beta': 0.3,
        #'ricap_use_same_random_value_on_batch': True,
        #'randaugment_N': 3,
        #'randaugment_M': 4,
        #'is_kuzushiji_gen': True,
        #'cutmix_alpha': 1.0
        }

    ## Augmentor使う場合のoption
    #train_augmentor_options = {
    #    'input_width': 100,
    #    'input_height': 100,
    #    'random_dist_prob': 0.3,
    #    'zoom_prob': 0.3,
    #    'zoom_min': 0.5
    #    , 'zoom_max': 1.9
    #    , 'flip_left_right': 0.3
    #    , 'flip_top_bottom': 0.3
    #    , 'random_erasing_prob': 0.3
    #    , 'random_erasing_area': 0.3
    #}

    return {
        #'output_dir': r'D:\work\signal_model\output\model\tf_base_class_all_py_time_series',
        'output_dir': r'D:\work\signal_model\output\model\tf_base_class_all_py_time_series_v2',
        'gpu_count': 1,
        #'img_rows': 1,
        'img_cols': 80,
        'channels': 3,
        'batch_size': 64,
        'classes': ['0', '1', '2'],
        'num_classes': 3,
        #'data_dir': r'D:\work\signal_model\output\dataset\all',
        #'data_dir': r'D:\work\signal_model\output\dataset\time_series',
        'data_dir': r'D:\work\signal_model\output\dataset\time_series_v2',
        # 'color_mode': 'rgb',
        'class_mode': 'categorical',  # generatorのラベルをone-hotベクトルに変換する場合。generatorのラベルを0か1のどちらかに変えるだけなら'binary'
        'activation': 'softmax',
        'loss': 'categorical_crossentropy',
        'metrics': ['accuracy',
                    keras.metrics.Precision(name='precision'),
                    keras.metrics.Recall(name='recall'),
                    keras.metrics.AUC(name='auc')],
        'model_path': None,
        'num_epoch': 200,
        #'n_multitask': 1,  # マルチタスクのタスク数
        #'multitask_pred_n_node': 1,  # マルチタスクの各クラス数
        # model param
        #'weights': 'imagenet',
        'choice_model': 'vgg',
        #'fcpool': 'GlobalAveragePooling2D',
        #'is_skip_bn': False,
        #'trainable': 'all',#249,
        #'efficientnet_num': 3,
        # full layer param
        #'fcs': [512, 256],
        #'drop': 0.3,
        #'is_add_batchnorm': False,# True,
        #'l2_rate': 1e-4,
        # optimizer param
        'choice_optim': 'sgd',  #'nadam',
        'lr': 0.001,  # 0.0001,
        'decay': 0.0,
        'my_IDG_options': my_IDG_options,
        #'train_augmentor_options': train_augmentor_options,
        #'TTA': '',  # 'flip',
        #'TTA_rotate_deg': 0,
        #'TTA_crop_num': 0,
        #'TTA_crop_size': [224, 224],
        #'preprocess': 1.0,
        #'resize_size': [100, 100],
        #'is_flow': False,
        #'is_flow_from_directory': True,
        #'is_flow_from_dataframe': False,
        #'is_lr_finder': False
    }


def train_directory(args):
    """指定ディレクトリについてモデル学習"""
    print('train_directory')
    # ### train validation data load ### #
    X_train, y_train, X_valid, y_valid, _, _ = get_dataset(classes=args['classes'], dataset_dir=args['data_dir'])

    # 4次元テンソルじゃないとImageDataGenerator使えない？
    #train_datagen = my_generator.MyImageDataGenerator(**args['my_IDG_options'])
    #train_gen = train_datagen.flow(X_train, y_train, batch_size=args['batch_size'])
    #valid_datagen = ImageDataGenerator()
    #valid_gen = valid_datagen.flow(X_valid, y_valid, batch_size=1)

    # ### model ### #
    if args['choice_model'] == 'resnet_2d':
        model = model_2d.create_resnet_2d(input_shape=(args['img_cols'], args['channels']),
                                          num_classes=args['num_classes'],
                                          activation=args['activation'])
    else:
        model = model_2d.create_vgg_2d(input_shape=(args['img_cols'], args['channels']),
                                       num_classes=args['num_classes'],
                                       activation=args['activation'])

    optim = define_model.get_optimizers(choice_optim=args['choice_optim'], lr=args['lr'], decay=args['decay'])
    model.compile(loss=args['loss'], optimizer=optim, metrics=args['metrics'])

    os.makedirs(args['output_dir'], exist_ok=True)
    cb = my_callback.get_base_cb(args['output_dir'], args['num_epoch'],
                                 early_stopping=args['num_epoch'] // 3,
                                 monitor='val_' + args['metrics'][0],
                                 metric=args['metrics'][0],
                                 )

    # ### train ### #
    start_time = time.time()
    hist = model.fit(
        #train_gen,
        X_train, y_train,
        #steps_per_epoch=X_train.shape[0] // args['batch_size'],
        batch_size=args['batch_size'],
        epochs=args['num_epoch'],
        #validation_data=valid_gen, validation_steps=X_valid.shape[0] // 1,
        validation_data=(X_valid, y_valid),
        verbose=2,  # 1:ログをプログレスバーで標準出力 2:最低限の情報のみ出す
        callbacks=cb)
    end_time = time.time()
    print("Elapsed Time : {:.2f}sec".format(end_time - start_time))

    model.save(os.path.join(args['output_dir'], 'model_last_epoch.h5'))

    plot_log.plot_results(args['output_dir'],
                          os.path.join(args['output_dir'], 'tsv_logger.tsv'),
                          acc_metric=args['metrics'][0])

    return hist


def pred_directory(args):
    """指定ディレクトリについてモデル予測"""
    # ### test data load ### #
    _, _, _, _, X_test, y_test = get_dataset(classes=args['classes'], dataset_dir=args['data_dir'])

    # generator predict TTA
    #load_model = keras.models.load_model(os.path.join(args['output_dir'], 'best_val_loss.h5'))
    #load_model = keras.models.load_model(os.path.join(args['output_dir'], 'best_val_accuracy.h5'))
    load_model = keras.models.load_model(os.path.join(args['output_dir'], 'optuna', 'best_trial_accuracy.h5'))
    #load_model = keras.models.load_model(os.path.join(args['output_dir'], 'optuna', 'best_trial_loss.h5'))
    pred_pb = load_model.predict(X_test)
    top_indices = np.argmax(pred_pb, axis=1)

    pred_id_list = []
    pred_score_list = []
    for i, top_id in enumerate(top_indices):
        pred_id_list.append(top_id)
        pred_score_list.append("{:.3}".format(pred_pb[i, top_id]))

    if args['classes'] is not None:
        # クラス名あればクラスid をクラス名に変換
        pred_name_list = []
        for pred_id in pred_id_list:
            pred_name_list.append(args['classes'][pred_id])

    # pred_df = pd.DataFrame({"Filename": '', "PredictionLabel": pred_name_list, "PredictionScore": pred_score_list})

    # 混同行列作成
    y_test = np.argmax(y_test, axis=1).astype(str)
    y_pred_name = np.array(pred_name_list)
    # print(y_test, y_pred_name)
    conf_matrix.make_confusion_matrix(args['classes'], y_test, y_pred_name, args['output_dir'], figsize=(6, 4), is_plot_confusion_matrix=True)


class OptunaCallback(keras.callbacks.Callback):
    """
    Optunaでの枝刈り（最終的な結果がどのぐらいうまくいきそうかを大まかに予測し、良い結果を残すことが見込まれない試行は、最後まで行うことなく早期終了）
    https://qiita.com/koshian2/items/107c386f81c9bb7f8df3
    """
    def __init__(self, trial, prune):
        self.trial = trial
        self.prune = prune

    def on_epoch_end(self, epoch, logs):
        current_val_error = logs["val_loss"]# 1.0 - logs["val_accuracy"]
        # epochごとの値記録（intermediate_values）
        self.trial.report(current_val_error, step=epoch)
        if self.prune == True:
            # 打ち切り判定
            if self.trial.should_prune(epoch):
                # MedianPrunerのデフォルトの設定で、最初の5trialをたたき台して使って、以降のtrialで打ち切っていく
                raise optuna.TrialPruned()


class Objective(object):

    def __init__(self, output_dir):
        self.output_dir = output_dir
        self.trial_best_loss = 1000.0
        self.trial_best_err = 1000.0

    def get_class_fine_tuning_parameter_suggestions(self, trial) -> dict:
        """
        Get parameter sample for class fine_tuning (like Keras)
        Args:
            trial(trial.Trial):
        Returns:
            dict: parameter sample generated by trial object
        """

        #my_IDG_options = {
        #    'rescale': 1.0 / 255.0,
        #    #'width_shift_range': trial.suggest_categorical('height_shift_range', [0.0, 0.25]),
        #    #'height_shift_range': trial.suggest_categorical('height_shift_range', [0.0, 0.25]),
        #    #'horizontal_flip': trial.suggest_categorical('horizontal_flip', [True, False]),
        #    #'vertical_flip': trial.suggest_categorical('vertical_flip', [True, False]),
        #    #'shear_range': trial.suggest_categorical('shear_range', [0.0, 20, 50]),
        #    'zoom_range': trial.suggest_categorical('zoom_range', [0.0, 0.2, 0.5]),
        #    #'rotation_range': trial.suggest_categorical('rotation_range', [0.0, 45, 60, 90]),
        #    #'channel_shift_range': trial.suggest_categorical('channel_shift_range', [0.0, 100, 200]),
        #    #'brightness_range': trial.suggest_categorical('brightness_range', [[1.0, 1.0], [0.3, 1.0]]),
        #    # MyImageDataGenerator param
        #    'random_erasing_prob': trial.suggest_categorical('random_erasing_prob', [0.0, 0.5]),
        #    'random_erasing_maxpixel': 255.,
        #    #'mix_up_alpha': trial.suggest_categorical('mix_up_alpha', [0.0, 0.2]),
        #    #'ricap_beta': trial.suggest_categorical('ricap_beta', [0.0, 0.3]),
        #    #'is_kuzushiji_gen': trial.suggest_categorical('is_kuzushiji_gen', [False]),
        #    'grayscale_prob': trial.suggest_categorical('grayscale_prob', [0.0, 0.3]),
        #    'cutmix_alpha': trial.suggest_categorical('cutmix_alpha', [0.0, 1.0]),
        #    'randaugment_N': trial.suggest_categorical('randaugment_N', [0, 3]),
        #    'randaugment_M': trial.suggest_categorical('randaugment_M', [0, 4]),
        #}

        ## Augmentor使う場合のoption
        #train_augmentor_options = {
        #    'rescale': 1.0/255.0,
        #    'rotate90': trial.suggest_categorical('rotate90', [0.0, 0.5]),
        #    'rotate180': trial.suggest_categorical('rotate180', [0.0, 0.5]),
        #    'rotate270': trial.suggest_categorical('rotate270', [0.0, 0.5]),
        #    'rotate_prob': trial.suggest_categorical('rotate_prob', [0.0, 0.5]),
        #    'rotate_max_left': trial.suggest_categorical('rotate_max_left', [20, 60, 90]),
        #    'rotate_max_right': trial.suggest_categorical('rotate_max_right', [20, 60, 90]),
        #    'crop_prob': trial.suggest_categorical('crop_prob', [0.0, 0.5]),
        #    'crop_area': trial.suggest_categorical('crop_area', [0.8, 0.5]),
        #    'crop_by_size_prob': trial.suggest_categorical('crop_by_size_prob', [0.0, 0.5]),
        #    'crop_by_width': trial.suggest_categorical('crop_by_width', [224]),
        #    'crop_by_height': trial.suggest_categorical('crop_by_height', [224]),
        #    'crop_by_centre': trial.suggest_categorical('crop_by_centre', [True, False]),
        #    'shear_prob': trial.suggest_categorical('shear_prob', [0.0, 0.5]),
        #    'shear_magni': trial.suggest_categorical('shear_magni', [20, 50]),
        #    'skew_prob': trial.suggest_categorical('skew_prob', [0.0, 0.5]),
        #    'skew_magni': trial.suggest_categorical('skew_magni', [20, 50]),
        #    'zoom_prob': trial.suggest_categorical('zoom_prob', [0.0, 0.5]),
        #    'zoom_min': trial.suggest_categorical('zoom_min', [0.2, 0.5, 0.9]),
        #    'zoom_max': trial.suggest_categorical('zoom_max', [1.2, 1.5, 1.9]),
        #    'flip_left_right': trial.suggest_categorical('flip_left_right', [0.0, 0.5]),
        #    'flip_top_bottom': trial.suggest_categorical('flip_top_bottom', [0.0, 0.5]),
        #    'random_erasing_prob': trial.suggest_categorical('random_erasing_prob', [0.0, 0.5]),
        #    'random_erasing_area': trial.suggest_categorical('random_erasing_area', [0.3]),
        #    'random_dist_prob': trial.suggest_categorical('random_dist_prob', [0.0, 0.5]),
        #    'random_dist_grid_width': trial.suggest_categorical('random_dist_grid_width', [4]),
        #    'random_dist_grid_height': trial.suggest_categorical('random_dist_grid_height', [4]),
        #    'random_dist_grid_height': trial.suggest_categorical('random_dist_grid_height', [4]),
        #    'random_dist_magnitude': trial.suggest_categorical('random_dist_magnitude', [8]),
        #    'black_and_white': trial.suggest_categorical('black_and_white', [0.0, 0.5]),
        #    'greyscale': trial.suggest_categorical('greyscale', [0.0, 0.5]),
        #    'invert': trial.suggest_categorical('invert', [0.0, 0.5])
        #}

        return {
            'output_dir': self.output_dir,
            'gpu_count': 1,
            #'img_rows': 1,
            'img_cols': 80,
            'channels': 3,
            'batch_size': 64,
            'classes': ['0', '1', '2'],
            'num_classes': 3,
            #'data_dir': r'D:\work\signal_model\output\dataset\all',
            'data_dir': r'D:\work\signal_model\output\dataset\time_series',
            #'color_mode': 'rgb',
            'class_mode': 'categorical',  # generatorのラベルをone-hotベクトルに変換する場合。generatorのラベルを0か1のどちらかに変えるだけなら'binary'
            'activation': 'softmax',
            'loss': 'categorical_crossentropy',
            'metrics': ['accuracy'],
            #'model_path': None,
            'num_epoch': 200,
            #'n_multitask': 1,  # マルチタスクのタスク数
            #'multitask_pred_n_node': 1,  # マルチタスクの各クラス数
            # model param
            #'weights': 'imagenet',
            'choice_model': trial.suggest_categorical('choice_model', ['vgg', 'resnet']),
            #'fcpool': 'GlobalAveragePooling2D',
            #'is_skip_bn': False,
            #'trainable': 'all',
            #'efficientnet_num': 3,
            # full layer param
            #'fcs': [512, 256],
            #'drop': 0.3,  # 0.0はドロップなし
            #'is_add_batchnorm': False,
            #'l2_rate': 1e-4,
            # optimizer param
            'choice_optim': trial.suggest_categorical('choice_optim', ['sgd', 'adam', 'adamax', 'nadam']),
            'lr': trial.suggest_categorical('lr', [1e-4, 1e-3, 1e-2, 1e-1]),
            'decay': 0.0,
            # data augment
            #'my_IDG_options': my_IDG_options,
            #'train_augmentor_options': train_augmentor_options,
            #'TTA': '',# 'flip',
            #'TTA_rotate_deg': 0,
            #'TTA_crop_num': 0,
            #'TTA_crop_size': [224, 224],
            #'preprocess': 1.0,
            #'resize_size': [100, 100],
            #'is_flow': False,
            #'is_flow_from_directory': True,
            #'is_flow_from_dataframe': False
        }

    def trial_train_directory(self, trial, args):
        keras.backend.clear_session()
        # ### train validation data load ### #
        X_train, y_train, X_valid, y_valid, _, _ = get_dataset(classes=args['classes'], dataset_dir=args['data_dir'])

        # ### model ### #
        if args['choice_model'] == 'vgg':
            model = model_2d.create_vgg_2d(input_shape=(args['img_cols'], args['channels']),
                                           num_classes=args['num_classes'],
                                           activation=args['activation'])
        else:
            model = model_2d.create_resnet_2d(input_shape=(args['img_cols'], args['channels']),
                                            num_classes=args['num_classes'],
                                            activation=args['activation'])

        optim = define_model.get_optimizers(choice_optim=args['choice_optim'], lr=args['lr'], decay=args['decay'])
        model.compile(loss=args['loss'], optimizer=optim, metrics=args['metrics'])

        os.makedirs(args['output_dir'], exist_ok=True)
        cb = my_callback.get_base_cb(args['output_dir'], args['num_epoch'],
                                     early_stopping=30,
                                     monitor='val_' + args['metrics'][0],
                                     metric=args['metrics'][0],
                                     )# args['num_epoch']//3
        cb.append(OptunaCallback(trial, True))

        # ### train ### #
        hist = model.fit(
            #train_gen,
            X_train, y_train,
            #steps_per_epoch=X_train.shape[0] // args['batch_size'],
            batch_size=args['batch_size'],
            epochs=args['num_epoch'],
            #validation_data=valid_gen, validation_steps=X_valid.shape[0] // 1,
            validation_data=(X_valid, y_valid),
            verbose=2,  # 1:ログをプログレスバーで標準出力 2:最低限の情報のみ出す
            callbacks=cb)

        return hist

    def __call__(self, trial):
        args = self.get_class_fine_tuning_parameter_suggestions(trial)
        print(args)
        # optuna v0.18以上だとtryで囲まないとエラーでtrial落ちる
        try:
            # train
            hist = self.trial_train_directory(trial, args)

            check_loss = np.min(hist.history['val_loss'])  # check_dataは小さい方が精度良いようにしておく
            if check_loss < self.trial_best_loss:
                print('check_loss, trial_best_loss:', str(check_loss), str(self.trial_best_loss))
                self.trial_best_loss = check_loss
                if os.path.exists(os.path.join(args['output_dir'], 'best_val_loss.h5')) == True:
                    shutil.copyfile(os.path.join(args['output_dir'], 'best_val_loss.h5'), os.path.join(args['output_dir'], 'best_trial_loss.h5'))

            check_err = 1.0 - np.max(hist.history['val_accuracy'])  # check_dataは小さい方が精度良いようにしておく
            if check_err < self.trial_best_err:
                print('check_err, trial_best_err:', str(check_err), str(self.trial_best_err))
                self.trial_best_err = check_err
                if os.path.exists(os.path.join(args['output_dir'], 'best_val_accuracy.h5')) == True:
                    shutil.copyfile(os.path.join(args['output_dir'], 'best_val_accuracy.h5'), os.path.join(args['output_dir'], 'best_trial_accuracy.h5'))

            # acc とloss の記録
            trial.set_user_attr('loss', np.min(hist.history['loss']))
            trial.set_user_attr('val_loss', np.min(hist.history['val_loss']))
            trial.set_user_attr('val_accuracy', np.max(hist.history['val_accuracy']))

            return np.min(hist.history['val_loss'])
        except Exception as e:
            traceback.print_exc()  # Exceptionが発生した際に表示される全スタックトレース表示
            return e  # 例外を返さないとstudy.csvにエラー内容が記載されない


if __name__ == '__main__':
    import matplotlib
    matplotlib.use('Agg')

    parser = argparse.ArgumentParser()
    parser.add_argument('-m', '--mode', choices=['train', 'predict', 'tuning'])
    parser.add_argument('--grad_cam_model_path', type=str, default=None)
    parser.add_argument('--grad_cam_image_dir', type=str, default=None)
    parser.add_argument('--study_name', help="Optuna trials study name", type=str, default='study')
    parser.add_argument('-n_t', '--n_trials', help="Optuna trials number", type=int, default=50)
    parser.add_argument('-t_out_dir', '--tuning_output_dir', help="Optuna trials output_dir", type=str,
                        default=r'D:\work\signal_model\output\model\tf_base_class_all_py_time_series\optuna')
    p_args = parser.parse_args()

    if p_args.mode == 'train':
        args = get_class_fine_tuning_parameter_base()
        train_directory(args)

    if p_args.mode == 'predict':
        args = get_class_fine_tuning_parameter_base()
        pred_directory(args)

    if p_args.grad_cam_model_path is not None and p_args.grad_cam_image_dir is not None:
        args = get_class_fine_tuning_parameter_base()
        for i, p in tqdm(enumerate(util.find_img_files(p_args.grad_cam_image_dir))):
            # 50枚ごとにモデル再ロード
            if i % 50 == 0:
                keras.backend.clear_session()
                keras.backend.set_learning_phase(0)
                model = keras.models.load_model(p_args.grad_cam_model_path, compile=False)
            # p_args.grad_cam_image_dirと同じディレクトリにGradCAM画像出力
            grad_cam.image2gradcam(model, p, is_gradcam_plus=False)

    if p_args.mode == 'tuning':
        os.makedirs(p_args.tuning_output_dir, exist_ok=True)
        study = optuna.create_study(direction='minimize',
                                    study_name=p_args.study_name,
                                    storage=f"sqlite:///{p_args.tuning_output_dir}/{p_args.study_name}.db",
                                    load_if_exists=True)
        study.optimize(Objective(p_args.tuning_output_dir), n_trials=p_args.n_trials)
        study.trials_dataframe().to_csv(f"{p_args.tuning_output_dir}/{p_args.study_name}_history.csv", index=False)
        print(f"\nstudy.best_params:\n{study.best_params}")
        print(f"\nstudy.best_trial:\n{study.best_trial}")
