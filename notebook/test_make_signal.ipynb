{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/81908/jupyter_notebook/tf_2_work/stock_work/signal_model/notebook\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\81908\\\\Anaconda3\\\\envs\\\\tfgpu\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pwd\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 株価の信号データ作成\n",
    "- https://www.youtube.com/watch?v=22Eq_0qADf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01 2000-05-06\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>25MA</th>\n",
       "      <th>75MA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0.515038</td>\n",
       "      <td>0.499729</td>\n",
       "      <td>0.497552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498374</td>\n",
       "      <td>0.497728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>0.514815</td>\n",
       "      <td>0.497828</td>\n",
       "      <td>0.498178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-11</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>0.485401</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>0.498814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>0.514815</td>\n",
       "      <td>0.496999</td>\n",
       "      <td>0.498904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-24</th>\n",
       "      <td>2000-04-24</td>\n",
       "      <td>0.638211</td>\n",
       "      <td>0.497055</td>\n",
       "      <td>0.500459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-25</th>\n",
       "      <td>2000-04-25</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.497583</td>\n",
       "      <td>0.500183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-26</th>\n",
       "      <td>2000-04-26</td>\n",
       "      <td>0.478102</td>\n",
       "      <td>0.494616</td>\n",
       "      <td>0.499725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-27</th>\n",
       "      <td>2000-04-27</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.496752</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-28</th>\n",
       "      <td>2000-04-28</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.493484</td>\n",
       "      <td>0.499358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date     close      25MA      75MA\n",
       "date                                               \n",
       "2000-01-05 2000-01-05  0.515038  0.499729  0.497552\n",
       "2000-01-06 2000-01-06  0.500000  0.498374  0.497728\n",
       "2000-01-07 2000-01-07  0.514815  0.497828  0.498178\n",
       "2000-01-11 2000-01-11  0.485401  0.497279  0.498814\n",
       "2000-01-12 2000-01-12  0.514815  0.496999  0.498904\n",
       "...               ...       ...       ...       ...\n",
       "2000-04-24 2000-04-24  0.638211  0.497055  0.500459\n",
       "2000-04-25 2000-04-25  0.478571  0.497583  0.500183\n",
       "2000-04-26 2000-04-26  0.478102  0.494616  0.499725\n",
       "2000-04-27 2000-04-27  0.507463  0.496752  0.500000\n",
       "2000-04-28 2000-04-28  0.462963  0.493484  0.499358\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-05-02</td>\n",
       "      <td>1350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-05-08</td>\n",
       "      <td>1380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-05-09</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-05-10</td>\n",
       "      <td>1470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-11</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-05-12</td>\n",
       "      <td>1420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-05-15</td>\n",
       "      <td>1450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-05-16</td>\n",
       "      <td>1430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-05-17</td>\n",
       "      <td>1420.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   close\n",
       "0  2000-05-02  1350.0\n",
       "1  2000-05-08  1380.0\n",
       "2  2000-05-09  1440.0\n",
       "3  2000-05-10  1470.0\n",
       "4  2000-05-11  1450.0\n",
       "5  2000-05-12  1420.0\n",
       "6  2000-05-15  1450.0\n",
       "7  2000-05-16  1430.0\n",
       "8  2000-05-17  1420.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date     2000-05-02\n",
      "close          1350\n",
      "Name: 0, dtype: object\n",
      "date     2000-05-17\n",
      "close          1420\n",
      "Name: 8, dtype: object\n",
      "(1, 80, 3)\n",
      "[[[0.51503759 0.499729   0.49755191]\n",
      "  [0.5        0.49837354 0.49772769]\n",
      "  [0.51481481 0.49782786 0.49817801]\n",
      "  [0.48540146 0.49727891 0.49881354]\n",
      "  [0.51481481 0.49699864 0.49890351]\n",
      "  [0.51459854 0.49616858 0.49908525]\n",
      "  [0.51438849 0.49505495 0.49862663]\n",
      "  [0.63475177 0.50110436 0.50100853]\n",
      "  [0.45       0.49751793 0.50036637]\n",
      "  [0.5        0.49640586 0.50045779]\n",
      "  [0.57236842 0.49944506 0.50128123]\n",
      "  [0.43865031 0.49833426 0.5002742 ]\n",
      "  [0.46078431 0.49721913 0.4996345 ]\n",
      "  [0.47959184 0.49804796 0.49963437]\n",
      "  [0.49305556 0.49776474 0.49963424]\n",
      "  [0.5        0.49943993 0.49954263]\n",
      "  [0.47902098 0.49719809 0.49926787]\n",
      "  [0.52857143 0.50224782 0.49880941]\n",
      "  [0.47916667 0.50084104 0.49853292]\n",
      "  [0.4929078  0.49887955 0.49843893]\n",
      "  [0.5        0.49859787 0.49898832]\n",
      "  [0.48571429 0.50028082 0.49889523]\n",
      "  [0.52173913 0.50168445 0.49898618]\n",
      "  [0.54255319 0.50336323 0.49963096]\n",
      "  [0.47959184 0.50307263 0.49935395]\n",
      "  [0.48611111 0.50194932 0.49898412]\n",
      "  [0.51408451 0.50250139 0.49953776]\n",
      "  [0.52083333 0.50277239 0.50018498]\n",
      "  [0.54081633 0.5049765  0.50055484]\n",
      "  [0.43464052 0.50165062 0.49963031]\n",
      "  [0.48601399 0.5005493  0.49990754]\n",
      "  [0.5        0.5        0.49990754]\n",
      "  [0.4858156  0.49423552 0.49953764]\n",
      "  [0.49280576 0.49613473 0.49944491]\n",
      "  [0.47101449 0.49501109 0.49879663]\n",
      "  [0.52238806 0.49275766 0.49888786]\n",
      "  [0.46350365 0.49410774 0.49879384]\n",
      "  [0.52272727 0.49661304 0.4986066 ]\n",
      "  [0.48518519 0.49688474 0.4984186 ]\n",
      "  [0.5        0.49715909 0.49869561]\n",
      "  [0.52255639 0.4980057  0.49962683]\n",
      "  [0.58088235 0.50199829 0.50111993]\n",
      "  [0.52040816 0.5017094  0.50214412]\n",
      "  [0.46666667 0.50113766 0.5015814 ]\n",
      "  [0.5        0.50142045 0.50065013]\n",
      "  [0.5137931  0.50198582 0.50111379]\n",
      "  [0.57482993 0.50566251 0.50222511]\n",
      "  [0.46835443 0.50337838 0.5012951 ]\n",
      "  [0.4869281  0.50112233 0.50138581]\n",
      "  [0.47350993 0.50084081 0.50119937]\n",
      "  [0.52721088 0.5025203  0.50138223]\n",
      "  [0.46688742 0.50055866 0.50046011]\n",
      "  [0.55479452 0.50195422 0.50082781]\n",
      "  [0.45454545 0.49832823 0.50018381]\n",
      "  [0.54761905 0.50307005 0.50055132]\n",
      "  [0.48701299 0.50306066 0.49990816]\n",
      "  [0.50657895 0.50332871 0.49944893]\n",
      "  [0.46732026 0.50248825 0.49926484]\n",
      "  [0.46621622 0.50137893 0.49834468]\n",
      "  [0.51398601 0.50302947 0.4981577 ]\n",
      "  [0.53448276 0.50356947 0.49861573]\n",
      "  [0.5        0.50492476 0.49916828]\n",
      "  [0.51333333 0.50462837 0.49953755]\n",
      "  [0.51973684 0.50596206 0.50037013]\n",
      "  [0.48709677 0.50538793 0.500185  ]\n",
      "  [0.5        0.5045552  0.50073985]\n",
      "  [0.49346405 0.50133369 0.50018483]\n",
      "  [0.51973684 0.50133191 0.50175552]\n",
      "  [0.51935484 0.50345837 0.50184468]\n",
      "  [0.5        0.50344645 0.5012889 ]\n",
      "  [0.46202532 0.501321   0.50064362]\n",
      "  [0.44736842 0.49630607 0.5006432 ]\n",
      "  [0.53472222 0.49894068 0.50128558]\n",
      "  [0.4261745  0.49655355 0.50027513]\n",
      "  [0.39130435 0.49361532 0.49908316]\n",
      "  [0.63821138 0.49705489 0.50045884]\n",
      "  [0.47857143 0.49758324 0.50018345]\n",
      "  [0.47810219 0.49461642 0.49972487]\n",
      "  [0.50746269 0.49675237 0.5       ]\n",
      "  [0.46296296 0.49348357 0.49935786]]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\81908\\jupyter_notebook\\tf_2_work\\stock_work\\signal_model\\code')\n",
    "import make_signal_all\n",
    "\n",
    "import datetime\n",
    "\n",
    "code = 1301#7974#2914\n",
    "\n",
    "start_date = '2000-01-01'\n",
    "d_start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "\n",
    "d_end_date = d_start_date + datetime.timedelta(weeks=4 * 4 + 2)  # 4ヶ月半後までデータとる\n",
    "print(d_start_date, d_end_date)\n",
    "\n",
    "output_dir = r'D:\\work\\signal_model\\output\\tmp'\n",
    "is_ticks = True\n",
    "figsize = (10, 10)\n",
    "    \n",
    "df, label, df_last_date, arr = make_signal_all.make_signal(code, d_start_date, d_end_date)\n",
    "print(label)\n",
    "display(df)\n",
    "display(df_last_date)\n",
    "\n",
    "print(df_last_date.iloc[0])\n",
    "print(df_last_date.iloc[-1])\n",
    "\n",
    "print(arr.shape)\n",
    "print(arr[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr_app = np.append(arr, arr, axis=0)\n",
    "print(arr_app.shape)\n",
    "#arr_app = arr_app.transpose(1, 0, 2)\n",
    "#print(arr_app.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.50189036, 0.49587449, 0.49836994],\n",
       "        [0.51006289, 0.49673465, 0.49816914],\n",
       "        [0.49003736, 0.49779967, 0.49770524],\n",
       "        [0.53773585, 0.49987749, 0.49898926],\n",
       "        [0.56969697, 0.50235248, 0.499761  ],\n",
       "        [0.5470255 , 0.50550068, 0.49942626],\n",
       "        [0.43614719, 0.50206667, 0.49900336],\n",
       "        [0.52890173, 0.50388218, 0.49984038],\n",
       "        [0.4752809 , 0.50280369, 0.50068648],\n",
       "        [0.4890553 , 0.50149434, 0.50059029],\n",
       "        [0.49242865, 0.50012033, 0.50027105],\n",
       "        [0.49941315, 0.49971124, 0.50038256],\n",
       "        [0.51115678, 0.50132387, 0.50020714],\n",
       "        [0.52497096, 0.50240385, 0.5005974 ],\n",
       "        [0.51983003, 0.50390887, 0.5013533 ],\n",
       "        [0.52222222, 0.50429974, 0.50128787],\n",
       "        [0.55978261, 0.50756368, 0.50214369],\n",
       "        [0.51589744, 0.50904134, 0.50242432],\n",
       "        [0.48939929, 0.50877316, 0.50237104],\n",
       "        [0.57653061, 0.51205965, 0.50357968],\n",
       "        [0.54028436, 0.51432205, 0.50428186],\n",
       "        [0.59111617, 0.51902223, 0.50551531],\n",
       "        [0.48538622, 0.51465437, 0.50578849],\n",
       "        [0.45381356, 0.51241069, 0.50534519],\n",
       "        [0.49555753, 0.5141146 , 0.50493206],\n",
       "        [0.53971441, 0.51574837, 0.50569648],\n",
       "        [0.47424893, 0.51391188, 0.50494857],\n",
       "        [0.42643172, 0.51060071, 0.50358331],\n",
       "        [0.53185925, 0.51063264, 0.50402343],\n",
       "        [0.55069124, 0.51041962, 0.50445089],\n",
       "        [0.57894737, 0.51225446, 0.50610035],\n",
       "        [0.52845528, 0.51582498, 0.50639814],\n",
       "        [0.42134387, 0.51072966, 0.50498987],\n",
       "        [0.499571  , 0.5114442 , 0.50533288],\n",
       "        [0.52145923, 0.51262905, 0.50564848],\n",
       "        [0.45798319, 0.51083501, 0.5046782 ],\n",
       "        [0.51754386, 0.51148185, 0.50496057],\n",
       "        [0.56465517, 0.51376164, 0.50601698],\n",
       "        [0.45465587, 0.51076186, 0.50517875],\n",
       "        [0.50508906, 0.51023431, 0.50545136],\n",
       "        [0.46835443, 0.50808673, 0.5048052 ],\n",
       "        [0.4795207 , 0.50525388, 0.50414742],\n",
       "        [0.42081851, 0.50156091, 0.50165773],\n",
       "        [0.52173913, 0.5027142 , 0.50164798],\n",
       "        [0.46453901, 0.49877755, 0.50112018],\n",
       "        [0.44362745, 0.49527906, 0.50059443],\n",
       "        [0.33636364, 0.4862092 , 0.49828766],\n",
       "        [0.56273292, 0.488439  , 0.49913186],\n",
       "        [0.59877265, 0.49331387, 0.50049051],\n",
       "        [0.5       , 0.4934503 , 0.50120465],\n",
       "        [0.48617021, 0.49130689, 0.50065756],\n",
       "        [0.4600863 , 0.49097273, 0.50027963],\n",
       "        [0.47752809, 0.49325153, 0.50041933],\n",
       "        [0.48563218, 0.49148371, 0.50041915],\n",
       "        [0.50874636, 0.48961716, 0.50042596],\n",
       "        [0.53468208, 0.48721911, 0.50116566],\n",
       "        [0.58994413, 0.48881203, 0.50213339],\n",
       "        [0.49436187, 0.49235925, 0.50222624],\n",
       "        [0.44845361, 0.49035091, 0.50152714],\n",
       "        [0.44565217, 0.48727432, 0.50058913],\n",
       "        [0.47701149, 0.4883187 , 0.50000693],\n",
       "        [0.49294118, 0.48712097, 0.49981298],\n",
       "        [0.47334123, 0.48292733, 0.49983372],\n",
       "        [0.55903834, 0.48702035, 0.5005197 ],\n",
       "        [0.53735632, 0.48797744, 0.50116352],\n",
       "        [0.49556787, 0.48927418, 0.50094772],\n",
       "        [0.48775737, 0.48970217, 0.50098829],\n",
       "        [0.43183099, 0.4908489 , 0.50038664],\n",
       "        [0.5241838 , 0.49065338, 0.50075227],\n",
       "        [0.38193625, 0.48776388, 0.49933794],\n",
       "        [0.57095047, 0.49262637, 0.50020703],\n",
       "        [0.56875   , 0.50228566, 0.50108323],\n",
       "        [0.57602339, 0.50294178, 0.50097178],\n",
       "        [0.5298913 , 0.50034106, 0.5014597 ],\n",
       "        [0.48311346, 0.49961359, 0.5018976 ],\n",
       "        [0.52254428, 0.50115967, 0.50216164],\n",
       "        [0.52624672, 0.50397465, 0.50238979],\n",
       "        [0.42378517, 0.50149308, 0.50147554],\n",
       "        [0.49667774, 0.50192004, 0.50102317],\n",
       "        [0.49666667, 0.5014429 , 0.50019761]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((0, 80, 3))\n",
    "arr_app = np.append(a, arr, axis=0)\n",
    "print(arr_app.shape)\n",
    "arr_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 80, 3)\n",
      "(34, 80, 3)\n",
      "(31, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr0 = np.load(r'D:\\work\\signal_model\\output\\tmp\\class_0_arr.npy')\n",
    "arr1 = np.load(r'D:\\work\\signal_model\\output\\tmp\\class_1_arr.npy')\n",
    "arr2 = np.load(r'D:\\work\\signal_model\\output\\tmp\\class_2_arr.npy')\n",
    "\n",
    "print(arr0.shape)\n",
    "print(arr1.shape)\n",
    "print(arr2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "119 + 24 + 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51503759, 0.499729  , 0.49755191],\n",
       "       [0.5       , 0.49837354, 0.49772769],\n",
       "       [0.51481481, 0.49782786, 0.49817801],\n",
       "       [0.48540146, 0.49727891, 0.49881354],\n",
       "       [0.51481481, 0.49699864, 0.49890351],\n",
       "       [0.51459854, 0.49616858, 0.49908525],\n",
       "       [0.51438849, 0.49505495, 0.49862663],\n",
       "       [0.63475177, 0.50110436, 0.50100853],\n",
       "       [0.45      , 0.49751793, 0.50036637],\n",
       "       [0.5       , 0.49640586, 0.50045779],\n",
       "       [0.57236842, 0.49944506, 0.50128123],\n",
       "       [0.43865031, 0.49833426, 0.5002742 ],\n",
       "       [0.46078431, 0.49721913, 0.4996345 ],\n",
       "       [0.47959184, 0.49804796, 0.49963437],\n",
       "       [0.49305556, 0.49776474, 0.49963424],\n",
       "       [0.5       , 0.49943993, 0.49954263],\n",
       "       [0.47902098, 0.49719809, 0.49926787],\n",
       "       [0.52857143, 0.50224782, 0.49880941],\n",
       "       [0.47916667, 0.50084104, 0.49853292],\n",
       "       [0.4929078 , 0.49887955, 0.49843893],\n",
       "       [0.5       , 0.49859787, 0.49898832],\n",
       "       [0.48571429, 0.50028082, 0.49889523],\n",
       "       [0.52173913, 0.50168445, 0.49898618],\n",
       "       [0.54255319, 0.50336323, 0.49963096],\n",
       "       [0.47959184, 0.50307263, 0.49935395],\n",
       "       [0.48611111, 0.50194932, 0.49898412],\n",
       "       [0.51408451, 0.50250139, 0.49953776],\n",
       "       [0.52083333, 0.50277239, 0.50018498],\n",
       "       [0.54081633, 0.5049765 , 0.50055484],\n",
       "       [0.43464052, 0.50165062, 0.49963031],\n",
       "       [0.48601399, 0.5005493 , 0.49990754],\n",
       "       [0.5       , 0.5       , 0.49990754],\n",
       "       [0.4858156 , 0.49423552, 0.49953764],\n",
       "       [0.49280576, 0.49613473, 0.49944491],\n",
       "       [0.47101449, 0.49501109, 0.49879663],\n",
       "       [0.52238806, 0.49275766, 0.49888786],\n",
       "       [0.46350365, 0.49410774, 0.49879384],\n",
       "       [0.52272727, 0.49661304, 0.4986066 ],\n",
       "       [0.48518519, 0.49688474, 0.4984186 ],\n",
       "       [0.5       , 0.49715909, 0.49869561],\n",
       "       [0.52255639, 0.4980057 , 0.49962683],\n",
       "       [0.58088235, 0.50199829, 0.50111993],\n",
       "       [0.52040816, 0.5017094 , 0.50214412],\n",
       "       [0.46666667, 0.50113766, 0.5015814 ],\n",
       "       [0.5       , 0.50142045, 0.50065013],\n",
       "       [0.5137931 , 0.50198582, 0.50111379],\n",
       "       [0.57482993, 0.50566251, 0.50222511],\n",
       "       [0.46835443, 0.50337838, 0.5012951 ],\n",
       "       [0.4869281 , 0.50112233, 0.50138581],\n",
       "       [0.47350993, 0.50084081, 0.50119937],\n",
       "       [0.52721088, 0.5025203 , 0.50138223],\n",
       "       [0.46688742, 0.50055866, 0.50046011],\n",
       "       [0.55479452, 0.50195422, 0.50082781],\n",
       "       [0.45454545, 0.49832823, 0.50018381],\n",
       "       [0.54761905, 0.50307005, 0.50055132],\n",
       "       [0.48701299, 0.50306066, 0.49990816],\n",
       "       [0.50657895, 0.50332871, 0.49944893],\n",
       "       [0.46732026, 0.50248825, 0.49926484],\n",
       "       [0.46621622, 0.50137893, 0.49834468],\n",
       "       [0.51398601, 0.50302947, 0.4981577 ],\n",
       "       [0.53448276, 0.50356947, 0.49861573],\n",
       "       [0.5       , 0.50492476, 0.49916828],\n",
       "       [0.51333333, 0.50462837, 0.49953755],\n",
       "       [0.51973684, 0.50596206, 0.50037013],\n",
       "       [0.48709677, 0.50538793, 0.500185  ],\n",
       "       [0.5       , 0.5045552 , 0.50073985],\n",
       "       [0.49346405, 0.50133369, 0.50018483],\n",
       "       [0.51973684, 0.50133191, 0.50175552],\n",
       "       [0.51935484, 0.50345837, 0.50184468],\n",
       "       [0.5       , 0.50344645, 0.5012889 ],\n",
       "       [0.46202532, 0.501321  , 0.50064362],\n",
       "       [0.44736842, 0.49630607, 0.5006432 ],\n",
       "       [0.53472222, 0.49894068, 0.50128558],\n",
       "       [0.4261745 , 0.49655355, 0.50027513],\n",
       "       [0.39130435, 0.49361532, 0.49908316],\n",
       "       [0.63821138, 0.49705489, 0.50045884],\n",
       "       [0.47857143, 0.49758324, 0.50018345],\n",
       "       [0.47810219, 0.49461642, 0.49972487],\n",
       "       [0.50746269, 0.49675237, 0.5       ],\n",
       "       [0.46296296, 0.49348357, 0.49935786]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22829, 80, 3)\n",
      "(22829, 80, 3)\n",
      "(22829, 80, 3)\n",
      "68487\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "_dir = r'D:\\work\\signal_model\\output\\dataset\\time_series\\train'\n",
    "\n",
    "arr0 = np.load(_dir + '/class_0_arr.npy')\n",
    "arr1 = np.load(_dir + '/class_1_arr.npy')\n",
    "arr2 = np.load(_dir + '/class_2_arr.npy')\n",
    "\n",
    "print(arr0.shape)\n",
    "print(arr1.shape)\n",
    "print(arr2.shape)\n",
    "\n",
    "print(arr0.shape[0] + arr1.shape[0] + arr2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12808, 80, 3)\n",
      "(3192, 80, 3)\n",
      "(3314, 80, 3)\n",
      "19314\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "_dir = r'D:\\work\\signal_model\\output\\dataset\\time_series\\validation'\n",
    "\n",
    "arr0 = np.load(_dir + '/class_0_arr.npy')\n",
    "arr1 = np.load(_dir + '/class_1_arr.npy')\n",
    "arr2 = np.load(_dir + '/class_2_arr.npy')\n",
    "\n",
    "print(arr0.shape)\n",
    "print(arr1.shape)\n",
    "print(arr2.shape)\n",
    "\n",
    "print(arr0.shape[0] + arr1.shape[0] + arr2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12774, 80, 3)\n",
      "(4509, 80, 3)\n",
      "(3066, 80, 3)\n",
      "20349\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "_dir = r'D:\\work\\signal_model\\output\\dataset\\time_series\\test'\n",
    "\n",
    "arr0 = np.load(_dir + '/class_0_arr.npy')\n",
    "arr1 = np.load(_dir + '/class_1_arr.npy')\n",
    "arr2 = np.load(_dir + '/class_2_arr.npy')\n",
    "\n",
    "print(arr0.shape)\n",
    "print(arr1.shape)\n",
    "print(arr2.shape)\n",
    "\n",
    "print(arr0.shape[0] + arr1.shape[0] + arr2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3192, 80, 3)\n",
      "(3192, 80, 3)\n",
      "(3192, 80, 3)\n",
      "9576\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "_dir = r'D:\\work\\signal_model\\output\\dataset\\time_series_v2\\orig\\validation'\n",
    "\n",
    "arr0 = np.load(_dir + '/class_0_arr.npy')\n",
    "arr1 = np.load(_dir + '/class_1_arr.npy')\n",
    "arr2 = np.load(_dir + '/class_2_arr.npy')\n",
    "\n",
    "print(arr0.shape)\n",
    "print(arr1.shape)\n",
    "print(arr2.shape)\n",
    "\n",
    "print(arr0.shape[0] + arr1.shape[0] + arr2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 80, 3)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 64)            640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 80, 64)            256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 80, 64)            0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 40, 128)           512       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 20, 256)           98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 256)           1024      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 126,467\n",
      "Trainable params: 125,571\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3303744 , 0.32830533, 0.34132022],\n",
       "       [0.3303744 , 0.32830533, 0.34132022]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "def create_vgg_2d(input_shape=(80, 3), n_class=3, activation=\"softmax\"):\n",
    "    \"\"\"2次元データのVGGっぽいの\"\"\"\n",
    "    inputs = layers.Input(input_shape)\n",
    "    x = inputs\n",
    "    for ch in [64, 128, 256]:\n",
    "        x = layers.Conv1D(ch, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        if ch != 256:\n",
    "            x = layers.AveragePooling1D(2)(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(n_class, activation=activation)(x)\n",
    "    return tf.keras.models.Model(inputs, x)\n",
    "\n",
    "model = create_vgg_2d()\n",
    "model.summary()\n",
    "\n",
    "model.predict(arr_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 80, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 80, 16)       160         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 80, 16)       64          conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 80, 16)       0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 80, 16)       784         re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 80, 16)       64          conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_47 (ReLU)                 (None, 80, 16)       0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 80, 16)       784         re_lu_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 80, 16)       0           conv1d_50[0][0]                  \n",
      "                                                                 conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 80, 16)       64          add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_48 (ReLU)                 (None, 80, 16)       0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 80, 16)       784         re_lu_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 80, 16)       64          conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_49 (ReLU)                 (None, 80, 16)       0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 80, 16)       784         re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 80, 16)       0           conv1d_52[0][0]                  \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 80, 16)       64          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_50 (ReLU)                 (None, 80, 16)       0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 80, 16)       784         re_lu_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 80, 16)       64          conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_51 (ReLU)                 (None, 80, 16)       0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 80, 16)       784         re_lu_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 80, 16)       0           conv1d_54[0][0]                  \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 80, 16)       64          add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_52 (ReLU)                 (None, 80, 16)       0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 80, 16)       784         re_lu_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 80, 16)       64          conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_53 (ReLU)                 (None, 80, 16)       0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 80, 16)       784         re_lu_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 80, 16)       0           conv1d_56[0][0]                  \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 80, 16)       64          add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_54 (ReLU)                 (None, 80, 16)       0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 80, 16)       784         re_lu_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 80, 16)       64          conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_55 (ReLU)                 (None, 80, 16)       0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 80, 16)       784         re_lu_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 80, 16)       0           conv1d_58[0][0]                  \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 80, 16)       64          add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_56 (ReLU)                 (None, 80, 16)       0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 80, 16)       784         re_lu_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 80, 16)       64          conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_57 (ReLU)                 (None, 80, 16)       0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 80, 16)       784         re_lu_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 80, 16)       0           conv1d_60[0][0]                  \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 80, 16)       64          add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_58 (ReLU)                 (None, 80, 16)       0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 80, 16)       784         re_lu_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 80, 16)       64          conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_59 (ReLU)                 (None, 80, 16)       0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 80, 16)       784         re_lu_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 80, 16)       0           conv1d_62[0][0]                  \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 80, 16)       64          add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_60 (ReLU)                 (None, 80, 16)       0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 40, 32)       1568        re_lu_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 40, 32)       128         conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_61 (ReLU)                 (None, 40, 32)       0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 40, 32)       3104        re_lu_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 40, 32)       1568        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 40, 32)       0           conv1d_64[0][0]                  \n",
      "                                                                 conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 40, 32)       128         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_62 (ReLU)                 (None, 40, 32)       0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 40, 32)       3104        re_lu_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 40, 32)       128         conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_63 (ReLU)                 (None, 40, 32)       0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 40, 32)       3104        re_lu_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 40, 32)       0           conv1d_67[0][0]                  \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 40, 32)       128         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_64 (ReLU)                 (None, 40, 32)       0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 40, 32)       3104        re_lu_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 40, 32)       128         conv1d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_65 (ReLU)                 (None, 40, 32)       0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 40, 32)       3104        re_lu_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 40, 32)       0           conv1d_69[0][0]                  \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 40, 32)       128         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_66 (ReLU)                 (None, 40, 32)       0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 40, 32)       3104        re_lu_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 40, 32)       128         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_67 (ReLU)                 (None, 40, 32)       0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 40, 32)       3104        re_lu_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 40, 32)       0           conv1d_71[0][0]                  \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 40, 32)       128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_68 (ReLU)                 (None, 40, 32)       0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 40, 32)       3104        re_lu_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 40, 32)       128         conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_69 (ReLU)                 (None, 40, 32)       0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 40, 32)       3104        re_lu_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 40, 32)       0           conv1d_73[0][0]                  \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 40, 32)       128         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_70 (ReLU)                 (None, 40, 32)       0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 40, 32)       3104        re_lu_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 40, 32)       128         conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_71 (ReLU)                 (None, 40, 32)       0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 40, 32)       3104        re_lu_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 40, 32)       0           conv1d_75[0][0]                  \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 40, 32)       128         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_72 (ReLU)                 (None, 40, 32)       0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 40, 32)       3104        re_lu_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 40, 32)       128         conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_73 (ReLU)                 (None, 40, 32)       0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 40, 32)       3104        re_lu_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 40, 32)       0           conv1d_77[0][0]                  \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 40, 32)       128         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_74 (ReLU)                 (None, 40, 32)       0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 20, 64)       6208        re_lu_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 20, 64)       256         conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_75 (ReLU)                 (None, 20, 64)       0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 20, 64)       12352       re_lu_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 20, 64)       6208        add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 20, 64)       0           conv1d_79[0][0]                  \n",
      "                                                                 conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 20, 64)       256         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_76 (ReLU)                 (None, 20, 64)       0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 20, 64)       12352       re_lu_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 20, 64)       256         conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_77 (ReLU)                 (None, 20, 64)       0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 20, 64)       12352       re_lu_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 20, 64)       0           conv1d_82[0][0]                  \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 20, 64)       256         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_78 (ReLU)                 (None, 20, 64)       0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 20, 64)       12352       re_lu_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 20, 64)       256         conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_79 (ReLU)                 (None, 20, 64)       0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 20, 64)       12352       re_lu_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 20, 64)       0           conv1d_84[0][0]                  \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 20, 64)       256         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_80 (ReLU)                 (None, 20, 64)       0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 20, 64)       12352       re_lu_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 20, 64)       256         conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_81 (ReLU)                 (None, 20, 64)       0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 20, 64)       12352       re_lu_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 20, 64)       0           conv1d_86[0][0]                  \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 20, 64)       256         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_82 (ReLU)                 (None, 20, 64)       0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 20, 64)       12352       re_lu_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 20, 64)       256         conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_83 (ReLU)                 (None, 20, 64)       0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, 20, 64)       12352       re_lu_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 20, 64)       0           conv1d_88[0][0]                  \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 20, 64)       256         add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_84 (ReLU)                 (None, 20, 64)       0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, 20, 64)       12352       re_lu_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 20, 64)       256         conv1d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_85 (ReLU)                 (None, 20, 64)       0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, 20, 64)       12352       re_lu_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 20, 64)       0           conv1d_90[0][0]                  \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 20, 64)       256         add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_86 (ReLU)                 (None, 20, 64)       0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 20, 64)       12352       re_lu_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 20, 64)       256         conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_87 (ReLU)                 (None, 20, 64)       0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 20, 64)       12352       re_lu_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 20, 64)       0           conv1d_92[0][0]                  \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 20, 64)       256         add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_88 (ReLU)                 (None, 20, 64)       0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 64)           0           re_lu_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            195         global_average_pooling1d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 234,147\n",
      "Trainable params: 230,979\n",
      "Non-trainable params: 3,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.39644468, 0.48411214, 0.11944313],\n",
       "       [0.39644468, 0.48411214, 0.11944313]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "def create_resnet_2d(input_shape=(80, 3), n_class=3, activation=\"softmax\"):\n",
    "    \"\"\"2次元データのresnet\"\"\"\n",
    "    def residual_block(inputs, ch, strides):\n",
    "        # main path\n",
    "        x = layers.BatchNormalization()(inputs)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.Conv1D(ch, 3, strides=strides, padding=\"same\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.Conv1D(ch, 3, padding=\"same\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
    "        # shortcut path\n",
    "        if inputs.shape[-1] != ch or strides > 1:\n",
    "            s = layers.Conv1D(ch, 3, strides=strides, padding=\"same\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-4))(inputs)\n",
    "        else:\n",
    "            s = inputs\n",
    "        # add\n",
    "        x = layers.Add()([x, s])\n",
    "        return x\n",
    "\n",
    "    def main():\n",
    "        inputs = layers.Input(input_shape)\n",
    "        x = layers.Conv1D(16, 3, padding=\"same\")(inputs)\n",
    "        for ch in [16, 32, 64]:\n",
    "            for i in range(7):\n",
    "                strides = 2 if i == 0 else 1\n",
    "                if ch == 16:\n",
    "                    strides = 1\n",
    "                x = residual_block(x, ch, strides)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ReLU()(x)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        x = layers.Dense(n_class, activation=activation)(x)\n",
    "\n",
    "        return tf.keras.models.Model(inputs, x)\n",
    "    \n",
    "    return main()\n",
    "\n",
    "model = create_resnet_2d(input_shape=(80, 3), n_class=3)\n",
    "model.summary()\n",
    "\n",
    "model.predict(arr_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86411, 21672, 28125]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "orig_npy_dir = r'C:\\Users\\81908\\jupyter_notebook\\tf_2_work\\stock_work\\signal_model\\output\\orig_date_all'\n",
    "classes = ['0', '1', '2']\n",
    "class_arrs = [np.load(os.path.join(orig_npy_dir, f'class_{c}_arr.npy')) for c in classes]\n",
    "len_arrs = [class_arr.shape[0] for class_arr in class_arrs]\n",
    "len_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86411, 80, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_arrs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54347826, 0.50027685, 0.49926335],\n",
       "       [0.52083333, 0.50055356, 0.49953926],\n",
       "       [0.48639456, 0.49861687, 0.49834055],\n",
       "       [0.47931034, 0.49778393, 0.49898421],\n",
       "       [0.52112676, 0.49805664, 0.49981512],\n",
       "       [0.4862069 , 0.49666203, 0.49990754],\n",
       "       [0.49300699, 0.49692995, 0.49990754],\n",
       "       [0.53521127, 0.49832027, 0.50036989],\n",
       "       [0.46598639, 0.49719574, 0.50018488],\n",
       "       [0.53521127, 0.49775028, 0.50027726],\n",
       "       [0.5       , 0.49689966, 0.50055437],\n",
       "       [0.47959184, 0.49604184, 0.50036938],\n",
       "       [0.51388889, 0.49829691, 0.50055386],\n",
       "       [0.47260274, 0.49943133, 0.50036904],\n",
       "       [0.52816901, 0.49914651, 0.50046113],\n",
       "       [0.47260274, 0.50113895, 0.49953909],\n",
       "       [0.48591549, 0.50483504, 0.4996311 ],\n",
       "       [0.53571429, 0.50141523, 0.50027678],\n",
       "       [0.4862069 , 0.50169587, 0.49990777],\n",
       "       [0.49300699, 0.50225734, 0.49953879],\n",
       "       [0.49295775, 0.50168919, 0.49889258],\n",
       "       [0.5212766 , 0.50393479, 0.50009239],\n",
       "       [0.50694444, 0.50335946, 0.50036952],\n",
       "       [0.49310345, 0.50251116, 0.50027703],\n",
       "       [0.54166667, 0.50333983, 0.50101551],\n",
       "       [0.52666667, 0.50277393, 0.50147561],\n",
       "       [0.5       , 0.50193638, 0.50184179],\n",
       "       [0.48051948, 0.50165654, 0.50128688],\n",
       "       [0.53311258, 0.50385888, 0.50220325],\n",
       "       [0.48076923, 0.5021966 , 0.5016488 ],\n",
       "       [0.50653595, 0.5030137 , 0.50192044],\n",
       "       [0.5       , 0.50327779, 0.50191676],\n",
       "       [0.46753247, 0.50054451, 0.50118429],\n",
       "       [0.52013423, 0.50272109, 0.50045496],\n",
       "       [0.51973684, 0.50217096, 0.50045475],\n",
       "       [0.5516129 , 0.50433252, 0.50163636],\n",
       "       [0.50613497, 0.50539229, 0.50172445],\n",
       "       [0.48170732, 0.50402253, 0.50126846],\n",
       "       [0.51242236, 0.50560897, 0.50045245],\n",
       "       [0.52453988, 0.50557769, 0.50126628],\n",
       "       [0.48802395, 0.50607501, 0.50126468],\n",
       "       [0.47575758, 0.50551326, 0.50126308],\n",
       "       [0.49378882, 0.50391645, 0.50081096],\n",
       "       [0.5       , 0.50442133, 0.50126047],\n",
       "       [0.48125   , 0.503884  , 0.50026976],\n",
       "       [0.5       , 0.5041269 , 0.50089896],\n",
       "       [0.50636943, 0.5035962 , 0.50035926],\n",
       "       [0.46835443, 0.50204761, 0.50008978],\n",
       "       [0.52614379, 0.50332056, 0.5003591 ],\n",
       "       [0.5       , 0.50178208, 0.50080768],\n",
       "       [0.46815287, 0.49949174, 0.50080703],\n",
       "       [0.47368421, 0.49847445, 0.50026879],\n",
       "       [0.52027027, 0.5       , 0.50008957],\n",
       "       [0.4602649 , 0.49719888, 0.49955217],\n",
       "       [0.54137931, 0.49948927, 0.49991039],\n",
       "       [0.46688742, 0.49795606, 0.49919348],\n",
       "       [0.51369863, 0.4984639 , 0.49955157],\n",
       "       [0.48648649, 0.49923077, 0.49937192],\n",
       "       [0.47260274, 0.49743392, 0.49910217],\n",
       "       [0.5       , 0.49665552, 0.49883178],\n",
       "       [0.52112676, 0.49535364, 0.49883041],\n",
       "       [0.47931034, 0.49429461, 0.49855882],\n",
       "       [0.51408451, 0.49556599, 0.49927837],\n",
       "       [0.5       , 0.49502227, 0.5       ],\n",
       "       [0.48611111, 0.49341759, 0.49936812],\n",
       "       [0.52112676, 0.49469918, 0.50063228],\n",
       "       [0.50689655, 0.4960032 , 0.50207619],\n",
       "       [0.48630137, 0.49571964, 0.50036033],\n",
       "       [0.49305556, 0.49543256, 0.5005403 ],\n",
       "       [0.50699301, 0.49649123, 0.50090001],\n",
       "       [0.5       , 0.49647887, 0.50080928],\n",
       "       [0.49305556, 0.49592281, 0.50116801],\n",
       "       [0.51398601, 0.49781659, 0.50107691],\n",
       "       [0.4862069 , 0.49617068, 0.50071717],\n",
       "       [0.55594406, 0.49835255, 0.50116456],\n",
       "       [0.44039735, 0.49724972, 0.49982105],\n",
       "       [0.53521127, 0.49972421, 0.5       ],\n",
       "       [0.49319728, 0.49862069, 0.50008949],\n",
       "       [0.5       , 0.50027624, 0.50035794],\n",
       "       [0.48630137, 0.49806683, 0.49991055]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_arrs[0][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "X_test, y_test = None, None\n",
    "for cla in ['0', '1', '2']:\n",
    "    X = np.load(os.path.join(r'D:\\work\\signal_model\\output\\dataset\\all', f'class_{cla}_test.npy'))\n",
    "    y = np.array([cla] * X.shape[0])\n",
    "    if X_test is None and y_test is None:\n",
    "        X_test = X\n",
    "        y_test = y\n",
    "    else:\n",
    "        X_test = np.append(X_test, X, axis=0)\n",
    "        y_test = np.append(y_test, y, axis=0)\n",
    "\n",
    "def label2onehot(labels: np.ndarray):\n",
    "    \"\"\"\n",
    "    sklearnでnp.ndarrayのラベルをonehot化\n",
    "    Args:\n",
    "        labels:onehot化するラベル名の配列.np.array(['high' 'high' 'low' 'low'])のようなの\n",
    "    Returns:\n",
    "        enc:ラベル名を0-nの連番にした配列。np.array([[0] [0] [1] [1]])のようなの\n",
    "        onehot:ラベル名をonehotにした配列。np.array([[1. 0.] [1. 0.] [0. 1.] [0. 1.]])のようなの\n",
    "    Usage:\n",
    "        labels = df['aaa'].values\n",
    "        enc, onehot = label2onehot(labels)\n",
    "    \"\"\"\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    enc = preprocessing.LabelEncoder().fit_transform(labels).reshape(-1,1)\n",
    "    onehot = OneHotEncoder().fit_transform(enc).toarray()\n",
    "    return enc, onehot\n",
    "\n",
    "_, y_test = label2onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3291, 80, 3) (3291, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
